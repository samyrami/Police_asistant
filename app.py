import pandas as pd
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
from langchain.callbacks.base import BaseCallbackHandler
from html_template import logo
from langchain.document_loaders import PyPDFLoader, DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
import re

# Load environment variables
load_dotenv()

# Get API key from environment variables
API_KEY = os.getenv("OPENAI_API_KEY")
if API_KEY is None:
    st.error("Error: OPENAI_API_KEY not found in environment variables")
    st.stop()
    
class LawDocumentProcessor:
    def __init__(self, pdf_directory="./leyes_pdf"):
        self.pdf_directory = pdf_directory
        self.embeddings = OpenAIEmbeddings()
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
    def load_documents(self):
        """Carga todos los PDFs del directorio especificado"""
        try:
            loader = DirectoryLoader(
                'data',
                glob="**/*.pdf",
                loader_cls=PyPDFLoader,
                show_progress=True
            )
            documents = loader.load()
        except Exception as e:
            st.error(f"Error loading PDFs: {str(e)}")
            documents = []
        return documents
    
    def process_documents(self):
        """Procesa los documentos y crea el almac√©n de vectores"""
        documents = self.load_documents()
        texts = self.text_splitter.split_documents(documents)
        
        # Crear el almac√©n de vectores con FAISS
        vector_store = FAISS.from_documents(texts, self.embeddings)
        
        # Guardar el √≠ndice localmente
        vector_store.save_local("faiss_index")
        return vector_store
    
    @staticmethod
    def load_vector_store():
        """Carga el almac√©n de vectores guardado"""
        try:
            if os.path.exists("faiss_index"):
                vector_store = FAISS.load_local(
                    "faiss_index", 
                    OpenAIEmbeddings(), 
                    allow_dangerous_deserialization=True  # Add this parameter
                )
                return vector_store
            return None
        except Exception as e:
            st.error(f"Error cargando el vector store: {str(e)}")
            return None

def setup_retrieval_chain(vector_store):
    """Configura la cadena de recuperaci√≥n para consultas"""
    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True
    )
    
    retrieval_chain = ConversationalRetrievalChain.from_llm(
        llm=ChatOpenAI(temperature=0),
        retriever=vector_store.as_retriever(search_kwargs={"k": 3}),
        memory=memory,
        return_source_documents=True
    )
    
    return retrieval_chain

# ... (c√≥digo anterior del app.py) ...

# A√±adir despu√©s de la inicializaci√≥n de variables globales
try:
    vector_store = LawDocumentProcessor.load_vector_store()
    if vector_store is None:
        st.warning("Procesando documentos legales por primera vez...")
        processor = LawDocumentProcessor()
        vector_store = processor.process_documents()
    
    retrieval_chain = setup_retrieval_chain(vector_store)
except Exception as e:
    st.error(f"Error cargando la base de conocimientos: {str(e)}")
    vector_store = None
    retrieval_chain = None



SYSTEM_PROMPT = """
[INSTRUCCIONES INTERNAS - NO MOSTRAR EN RESPUESTA]
- S√© extremadamente preciso con citaciones legales y montos
- Verifica m√∫ltiples veces la informaci√≥n antes de responder
- No hagas interpretaciones sin base legal
- Indica expl√≠citamente si no encuentras informaci√≥n exacta
- Contrasta siempre con m√∫ltiples fuentes
- Advierte sobre cualquier ambig√ºedad en la norma

[FORMATO DE RESPUESTA A UTILIZAR]

‚Ä¢ Tipo de Infracci√≥n: [ESPECIFICAR c√≥digo exacto de la infracci√≥n]

‚Ä¢ Descripci√≥n Legal: [Cita TEXTUAL de la norma que describe la infracci√≥n]

‚Ä¢ Base Legal: [Art√≠culo COMPLETO con n√∫mero exacto y texto √≠ntegro]

‚Ä¢ Sanci√≥n Espec√≠fica:
  - Valor Monetario: [Cantidad EXACTA en SMDLV/SMLMV]
  - Medidas Adicionales: [Todas las medidas aplicables con duraci√≥n]

‚Ä¢ Procedimiento Detallado:
  - Base legal del procedimiento
  - Pasos espec√≠ficos numerados
  - Plazos exactos para cada acci√≥n

‚Ä¢ Medidas Inmediatas del Agente:
  - Acciones obligatorias
  - Documentaci√≥n requerida
  - Procedimientos de aseguramiento

‚Ä¢ Derechos del Ciudadano:
  - Base legal de cada derecho
  - T√©rminos exactos para recursos
  - Autoridades competentes

[REQUISITOS DE CONTENIDO]

I. Clasificaci√≥n de Infracciones:
A. Infracciones de Tr√°nsito:
   - Monetarias: Especificar EXACTAMENTE el valor en SMDLV o SMLMV
   - No Monetarias: Detallar duraci√≥n exacta de suspensiones/retenciones
   - Combinadas: Especificar TODAS las sanciones aplicables

B. Comportamientos Contrarios a la Convivencia:
   - Citar el art√≠culo EXACTO del C√≥digo Nacional de Seguridad
   - Especificar TODAS las medidas correctivas aplicables
   - Detallar el procedimiento paso a paso

II. Debido Proceso (Obligatorio incluir):
1. N√∫mero y texto COMPLETO del art√≠culo infringido
2. Procedimiento espec√≠fico con base legal
3. Derechos del ciudadano citando la norma exacta
4. Recursos procedentes con t√©rminos precisos
"""


def get_article_text(vector_store, article_reference):
    """
    Busca y retorna el texto completo de un art√≠culo espec√≠fico.
    """
    # Realizar una b√∫squeda espec√≠fica por el n√∫mero de art√≠culo
    similar_docs = vector_store.similarity_search(
        f"Art√≠culo {article_reference}",
        k=3
    )
    
    # Filtrar y extraer el texto completo del art√≠culo
    for doc in similar_docs:
        content = doc.page_content
        if f"Art√≠culo {article_reference}" in content:
            # Extraer el texto completo del art√≠culo
            return content
    
    return None

def calcular_sancion(detalles_sancion):
    """
    Calcula y detalla sanciones complejas
    
    :param detalles_sancion: Diccionario con detalles de la sanci√≥n
    :return: Diccionario con informaci√≥n detallada
    """
    # Valor del SMMLV para 2024 (actualizable)
    SMMLV_2024 = 1_300_000
    SMDLV_2024 = SMMLV_2024 / 30

    resultado = {
        "sanciones": [],
        "procedimiento_detallado": "",
        "derechos_infractor": ""
    }

    # Manejo de sanciones monetarias
    if "monetaria" in detalles_sancion:
        unidad = detalles_sancion["monetaria"].get("unidad", "SMDLV")
        cantidad = detalles_sancion["monetaria"].get("cantidad", 0)
        
        if unidad == "SMDLV":
            valor_total = SMDLV_2024 * cantidad
            resultado["sanciones"].append({
                "tipo": "Multa",
                "unidad": "SMDLV",
                "cantidad": cantidad,
                "valor": f"${valor_total:,.0f}"
            })

    # Sanciones no monetarias
    if "no_monetaria" in detalles_sancion:
        sanciones_no_monetarias = detalles_sancion["no_monetaria"]
        for sancion in sanciones_no_monetarias:
            resultado["sanciones"].append({
                "tipo": sancion,
                "descripcion": {
                    "Suspensi√≥n de Licencia": "Retiro temporal del derecho a conducir",
                    "Retenci√≥n de Veh√≠culo": "Inmovilizaci√≥n del veh√≠culo en dep√≥sito oficial"
                }.get(sancion, sancion)
            })

    # Procedimiento detallado
    resultado["procedimiento_detallado"] = """
    Procedimiento Est√°ndar:
    1. Detecci√≥n de la Infracci√≥n
    2. Registro en Formato √önico de Comparendo
    3. Notificaci√≥n al Infractor
    4. Opciones de Pago/Descargos
    5. Posible Impugnaci√≥n
    """

    # Derechos del Infractor
    resultado["derechos_infractor"] = """
    Derechos del Infractor:
    - Derecho a presentar descargos
    - Solicitar pr√°ctica de pruebas
    - Interponer recursos de reposici√≥n
    - Acceso a defensa t√©cnica
    - Principio de presunci√≥n de inocencia
    """

    return resultado
    

def display_response(response_text, container):
    """Display the response using Streamlit components with article text."""
    if '|' in response_text:
        df, other_text = extract_table_data(response_text)
        if df is not None:
            if other_text:
                container.markdown(other_text)
            
            container.markdown("### Detalles de la Infracci√≥n")
            
            # Buscar referencias a art√≠culos en la tabla
            for index, row in df.iterrows():
                if row['Campo'] == 'Base Legal' and row['Valor']:
                    # Extraer n√∫mero de art√≠culo (ajustar seg√∫n el formato)
                    article_match = re.search(r'Art√≠culo (\d+)', row['Valor'])
                    if article_match:
                        article_num = article_match.group(1)
                        article_text = get_article_text(vector_store, article_num)
                        if article_text:
                            # A√±adir el texto completo del art√≠culo a la tabla
                            df.loc[len(df)] = ['Texto Completo del Art√≠culo', article_text]
            
            styled_df = df.style.set_properties(**{
                'background-color': '#f0f2f6',
                'color': '#1f1f1f',
                'border': '2px solid #1e3d59',
                'white-space': 'pre-wrap'  # Para preservar saltos de l√≠nea
            })
            
            container.dataframe(
                styled_df,
                use_container_width=True,
                hide_index=True,
                column_config={
                    "Campo": st.column_config.TextColumn(
                        "Campo",
                        help="Categor√≠a de la informaci√≥n",
                        width="medium",
                    ),
                    "Valor": st.column_config.TextColumn(
                        "Valor",
                        help="Informaci√≥n detallada",
                        width="large",
                    )
                }
            )
        else:
            container.markdown(response_text)
    else:
        container.markdown(response_text)   
 
class StreamHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token

        display_response(self.text, self.container)

def extract_table_data(markdown_text):
    """Extract table data from markdown and convert to DataFrame."""
    try:
        # Find table in text using regex
        table_pattern = r'\|.*\|'
        table_rows = re.findall(table_pattern, markdown_text)
        
        if not table_rows:
            return None, None
            
        # Process table rows
        headers = ['Campo', 'Valor']
        data = []
        
        for row in table_rows[2:]:
            values = [col.strip() for col in row.split('|')[1:-1]]
            if len(values) == 2:
                data.append(values)
        
        df = pd.DataFrame(data, columns=headers)
        
        pre_table = markdown_text.split('|')[0].strip()
        post_table = markdown_text.split('|')[-1].strip()
        other_text = f"{pre_table}\n\n{post_table}".strip()
        
        return df, other_text
    except Exception as e:
        st.error(f"Error procesando la tabla: {str(e)}")
        return None, None



def search_laws(query):
    """Buscar en los documentos legales vectorizados con m√°s detalles."""
    if vector_store is None:
        st.error("Base de conocimientos no inicializada")
        return None
    
    # Realizar una b√∫squeda de similitud en el vector store
    similar_docs = vector_store.similarity_search(query, k=5)
    
    # Preparar los resultados
    results = []
    for doc in similar_docs:
        # Extraer informaci√≥n del contexto
        content = doc.page_content
        source = doc.metadata.get('source', 'Documento desconocido')
        page = doc.metadata.get('page', 'N/A')
        
        results.append({
            'Art√≠culo/C√≥digo': f"Fuente: {source}, P√°gina: {page}",
            'Contenido Relevante': content[:500] + '...',  # Mostrar un extracto m√°s largo
        })
    
    # Convertir a DataFrame para mostrar resultados
    results_df = pd.DataFrame(results)
    return results_df


def get_chat_response(prompt, temperature=0.3):
    """Generate chat response using the selected LLM with improved context handling."""
    try:
        response_placeholder = st.empty()
        stream_handler = StreamHandler(response_placeholder)
        
        # Primero, buscar contexto relevante en la base de datos
        relevant_context = search_laws(prompt)
        
        # Crear un prompt enriquecido con el contexto
        enhanced_prompt = f"""
        Consulta: {prompt}
        
        Contexto relevante encontrado en la base de datos:
        {relevant_context.to_string() if not relevant_context.empty else 'No se encontr√≥ contexto espec√≠fico'}
        
        Por favor, proporciona una respuesta detallada basada en este contexto y las normas aplicables.
        """
        
        chat_model = ChatOpenAI(
            model="gpt-4o",
            temperature=temperature,
            api_key=API_KEY,
            streaming=True,
            callbacks=[stream_handler]
        )
        
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=enhanced_prompt)
        ]
        
        if "messages" in st.session_state:
            for msg in st.session_state.messages[-3:]:
                if msg["role"] == "user":
                    messages.append(HumanMessage(content=msg["content"]))
                else:
                    messages.append(SystemMessage(content=msg["content"]))
        
        response = chat_model.invoke(messages)
        return stream_handler.text
        
    except Exception as e:
        st.error(f"Error generando respuesta: {str(e)}")
        return "Lo siento, ocurri√≥ un error al procesar su solicitud."


def ensure_directory_exists():
    """Ensure necessary directories exist."""
    directories = ["./faiss_index", "./leyes_pdf"]
    for directory in directories:
        if not os.path.exists(directory):
            os.makedirs(directory)

def check_startup_health():
    """Verify all components are ready."""
    try:
        # Check API key
        if not API_KEY:
            raise ValueError("OPENAI_API_KEY not set")
            
        # Check directories
        ensure_directory_exists()
        
        # Check vector store
        vector_store = LawDocumentProcessor.load_vector_store()
        if vector_store is None:
            st.warning("Initializing knowledge base...")
            processor = LawDocumentProcessor()
            vector_store = processor.process_documents()
            
        return True
    except Exception as e:
        st.error(f"Startup health check failed: {str(e)}")
        return False

# Add this at the start of your main function
if not check_startup_health():
    st.stop()

def main():
    ensure_directory_exists()
    st.set_page_config(page_title="PoliciApp", layout="centered")
    st.write(logo, unsafe_allow_html=True)
    st.title("PoliciApp", anchor=False)
    st.markdown("**Asistente virtual para procedimientos de multas y comparendos**")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    with st.sidebar:
        st.markdown("""
        **Bienvenido al Sistema de Consulta de Infracciones**
        
        Esta herramienta est√° dise√±ada para ayudarte a:
        - Consultar r√°pidamente infracciones de tr√°nsito
        - Verificar sanciones aplicables
        - Conocer el procedimiento correcto
        - Informar sobre derechos del infractor
        
        **Para comenzar:**
        1. Escribe 'MULTA:' seguido de la situaci√≥n
        2. O busca directamente en la base de datos de infracciones
        """)
        
        # B√∫squeda en base de datos
        search_query = st.text_input("Buscar en base de datos de infracciones:")
        if search_query:
            results = search_laws(search_query)
            if not results.empty:
                st.dataframe(results)
            else:
                st.info("No se encontraron resultados")

        if st.button("Borrar Historial"):
            st.session_state.messages = []
            st.experimental_rerun()

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and '|' in message["content"]:
                display_response(message["content"], st)
            else:
                st.markdown(message["content"])

    if prompt := st.chat_input("Describe la situaci√≥n... (Inicia con MULTA: para procesar una infracci√≥n)"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user", avatar="üëÆ"):
            st.markdown(prompt)
        
        with st.chat_message("assistant", avatar="üöì"):
            is_multa = prompt.upper().startswith("MULTA:")
            if is_multa:
                multa_content = prompt[6:].strip()
                response = get_chat_response(multa_content)
            else:
                response = get_chat_response(prompt)
            
            st.session_state.messages.append({"role": "assistant", "content": response})

if __name__ == "__main__":
    main()